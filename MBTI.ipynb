{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBTI Analysis with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import urllib.request\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Web for Text Information\n",
    "\n",
    "This part parses the front page of each subforum, and then extracts the text from the forum posts. \n",
    "\n",
    "The result looks like a TXT file for each type, with posts written inside, seperated by the three newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gettype = r\"\\b[A-Z]{4}\\b\"\n",
    "getpagenumber = r\"-(\\d*?)\\.html\"\n",
    "\n",
    "webpages = [\"http://personalitycafe.com/istj-forum-duty-fulfillers/\", \n",
    "            \"http://personalitycafe.com/intp-forum-thinkers/\",\n",
    "            \"http://personalitycafe.com/isfj-forum-nurturers/\",\n",
    "            \"http://personalitycafe.com/estj-forum-guardians/\",\n",
    "            \"http://personalitycafe.com/esfj-forum-caregivers/\",\n",
    "            \"http://personalitycafe.com/istp-forum-mechanics/\",\n",
    "            \"http://personalitycafe.com/isfp-forum-artists/\",\n",
    "            \"http://personalitycafe.com/estp-forum-doers/\",\n",
    "            \"http://personalitycafe.com/esfp-forum-performers/\",\n",
    "            \"http://personalitycafe.com/intj-forum-scientists/\",\n",
    "            \"http://personalitycafe.com/entj-forum-executives/\",\n",
    "            \"http://personalitycafe.com/entp-forum-visionaries/\",\n",
    "            \"http://personalitycafe.com/infj-forum-protectors/\",\n",
    "            \"http://personalitycafe.com/infp-forum-idealists/\",\n",
    "            \"http://personalitycafe.com/enfj-forum-givers/\",\n",
    "            \"http://personalitycafe.com/enfp-forum-inspirers/\"]\n",
    "\n",
    "def gettextfrompersonalitycaffee(webpage):\n",
    "    page = urllib.request.urlopen(webpage)\n",
    "    content = page.read()\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    allposts = soup.find_all(\"div\", class_=\"content\")\n",
    "    users = soup.find_all(\"div\", class_=\"userinfo\")\n",
    "    infos = zip(users, allposts)\n",
    "    for user, post in infos:\n",
    "        post = post.find_all(\"blockquote\")[0]\n",
    "        if \"<script>\" in post:\n",
    "            post = post.script.decompose()\n",
    "        post = post.get_text()\n",
    "        pertype = re.search(gettype, user.get_text())\n",
    "        if not pertype:\n",
    "            continue\n",
    "        pertype = pertype.group()\n",
    "        with open(pertype, \"a\") as write:\n",
    "            write.write(post)\n",
    "            write.write(\"\\n\\n\\n\\n\\n\")\n",
    "            \n",
    "def getnumberofpages(webpage):\n",
    "    page = urllib.request.urlopen(webpage)\n",
    "    content = page.read()\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    numbers = soup.find_all(\"span\", class_=\"first_last\")\n",
    "    if not numbers:\n",
    "        return None\n",
    "    link = numbers[-1].find_all(\"a\")\n",
    "    link = link[0].get(\"href\")\n",
    "    number = re.search(getpagenumber, link)\n",
    "    number = number.group().replace(\".html\", \"\").replace(\"-\", \"\")\n",
    "    return int(number)\n",
    "\n",
    "def getlinksfromfrontpage(webpage):\n",
    "    allthreads = []\n",
    "    page = urllib.request.urlopen(webpage)\n",
    "    content = page.read()\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    threads = soup.find_all(\"h3\", class_=\"threadtitle\")\n",
    "    for thread in threads:\n",
    "        link = thread.find_all(\"a\")\n",
    "        link = link[0].get(\"href\")\n",
    "        allthreads.append(link)\n",
    "    return allthreads\n",
    "\n",
    "def getallthreadlinks(website, number):\n",
    "    allwebsites = []\n",
    "    if not number:\n",
    "        return [website]\n",
    "    for i in range(number):\n",
    "        webpage = website.split(\".\")\n",
    "        webpage[-2] = webpage[-2] + \"-\" + str(i + 1)\n",
    "        webpage = \".\".join(webpage)\n",
    "        allwebsites.append(webpage)\n",
    "    return allwebsites\n",
    "\n",
    "for webpage in webpages:\n",
    "    alllinks = getlinksfromfrontpage(webpage)\n",
    "    for link in alllinks:\n",
    "        number = getnumberofpages(link)\n",
    "        if not number:\n",
    "            allthreadlinks = [link]\n",
    "        else:\n",
    "            allthreadlinks = getallthreadlinks(link, number)\n",
    "        for treadlink in allthreadlinks:\n",
    "            gettextfrompersonalitycaffee(treadlink)\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "Here I originally used vim:\n",
    "    \n",
    "    :%s/(function(w,d,s,i)/\\r(function(w,d,s,i)/g \n",
    "    :g/(function(w,d,s,i)/d\n",
    "        \n",
    "I did not think it through how to do it in python yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = [\"ENFJ\",\n",
    "             \"ENFP\",\n",
    "             \"ENTJ\",\n",
    "             \"ENTP\",\n",
    "             \"ESFJ\",\n",
    "             \"ESFP\",\n",
    "             \"ESTJ\",\n",
    "             \"ESTP\",\n",
    "             \"INFJ\",\n",
    "             \"INFP\",\n",
    "             \"INTJ\",\n",
    "             \"INTP\",\n",
    "             \"ISFJ\",\n",
    "             \"ISFP\",\n",
    "             \"ISTJ\",\n",
    "             \"ISTP\"]\n",
    "\n",
    "texts = list()\n",
    "types = list()\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(filename, \"r\") as read:\n",
    "        content = read.readlines()\n",
    "    content = \"\".join(content)\n",
    "    content = content.split(\"\\n\\n\\n\")\n",
    "    content = [post.strip() for post in content]\n",
    "    for post in content:\n",
    "        texts.append(post)\n",
    "        types.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preparing data for building the model\n",
    "data = [element for element in zip(texts, types)]\n",
    "random.shuffle(data)\n",
    "texts2 = [element[0] for element in data]\n",
    "types2 = [element[1] for element in data]\n",
    "\n",
    "number70 = int(round(len(texts2)*0.7,0))\n",
    "\n",
    "texts_train = texts2[:number70]\n",
    "types_train = types2[:number70]\n",
    "texts_test = texts2[number70:]\n",
    "types_test = types2[number70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#building the model\n",
    "model = Pipeline([('vect', CountVectorizer(stop_words=\"english\")),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('svc', LinearSVC()),\n",
    "                    ])\n",
    "\n",
    "dtfitted = model.fit(texts_train, types_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.479948548017\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADwpJREFUeJzt3X2MXNV9xvHvs7sYdzGNDUsSgu0aKoREo7ZYC8JJRaO6\ndo0LOJUiYatp3RApilpaqBoljpCaqH81TZu+Roko0NLWgqgONJYFDRZJVIqKG3BtwDGJDXVhjYNt\ngkzaAPZ6f/1j7kbj9Yw9c+4Ls3uej7Sal3vP3t+emWfuzN175igiMLP8DL3dBZjZ28PhN8uUw2+W\nKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZWqkyY2NjY3F0qVL+243NOTXKLNeHDhwgKNHj6qXdRsN\n/9KlS3nsscf6bjc6Otp3G6mnv/80Kac7p25rNkg9/TulnV/kyxsfH+95Xfe2WaZKhV/SGknflbRf\n0qaqijKz+iWHX9Iw8EXgeuBKYIOkK6sqzMzqVWbPfw2wPyJeiIjjwP3AumrKMrO6lQn/JcBLbbcn\nivvMbBYoE/5Oh7hPO8Qr6WOSnpT05NGjR0tszsyqVCb8E8CSttuLgZdnrhQRd0bEeESMj42Nldic\nmVWpTPi/DVwu6VJJ84D1wNZqyjKzuiWf5BMRk5JuBb4ODAP3RMSeyiozs1qVOsMvIh4CHqqoFjNr\nkM/wM8uUw2+WqUYH9gwNDSUN0pmYmOi7zZIlS86+UgcnT57su83ISKPd2KiU/gCYmprqu03qAKnh\n4eG+2zQ9iGgQ58fwnt8sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNM\nOfxmmWp8RErK4I2UQTpvvPFG320A5s+fn9RurkoZNFOm3Vw1iLM6ec9vlimH3yxTDr9ZpspM17VE\n0jcl7ZW0R9JtVRZmZvUqc8BvEviDiNgp6XzgKUnbI+I7FdVmZjVK3vNHxKGI2Flc/yGwF0/XZTZr\nVPKZX9Iy4CpgR4dlP56u68iRI1VszswqUDr8khYAXwVuj4jXZy5vn67roosuKrs5M6tIqfBLOodW\n8DdHxAPVlGRmTShztF/A3cDeiPhCdSWZWRPK7PnfD/wG8EuSdhU/ayuqy8xqVmaizn8HBu+EZTPr\nic/wM8vUrJhnKmXqp9TRea+++mrfbcbGxpK2NRuk9P1sMBtGHdY9xZf3/GaZcvjNMuXwm2XK4TfL\nlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfL1KwY2DM01Nxr1FwepJNiNgyAmavqnuLL\ne36zTDn8Zply+M0yVcVXdw9L+i9J26ooyMyaUcWe/zZas/WY2SxS9nv7FwO/CtxVTTlm1pSye/6/\nAD4JzM0vejObw8pM2nEDcDginjrLep6rz2wAlZ204yZJB4D7aU3e8U8zV/JcfWaDqcwU3Z+OiMUR\nsQxYD3wjIj5cWWVmViv/n98sU5Wc2x8R3wK+VcXvMrNmeM9vlimH3yxTDr9Zphx+s0w5/GaZcvjN\nMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTZSftWChp\ni6TnJO2VtKKqwsysXmW/w+8vgX+NiA9JmgeMVlCTmTUgOfySfhK4DvgtgIg4Dhyvpiwzq1uZt/2X\nAUeAvytm6b1L0nkV1WVmNSsT/hFgOfCliLgK+D9g08yVPF2X2WAqE/4JYCIidhS3t9B6MTiFp+sy\nG0xlpuv6PvCSpCuKu1YC36mkKjOrXdmj/b8LbC6O9L8AfKR8SWbWhFLhj4hdwHhFtZhZg3yGn1mm\nKpmo0wZfRCS1k1RxJTYovOc3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yp\nh98sUw6/WaYcfrNMNT6q7+TJk323OX68/y8FnjdvXt9tACYnJ/tuc+655yZtazbYsmVLUrurr766\n7zYLFy5M2lbKyMMFCxYkbStVyqjKqampWrfjPb9Zphx+s0yVna7r9yXtkfSspPskza+qMDOrV3L4\nJV0C/B4wHhHvBYaB9VUVZmb1Kvu2fwT4CUkjtObpe7l8SWbWhDLf238Q+FPgReAQcCwiHqmqMDOr\nV5m3/YuAdcClwHuA8yR9uMN6nq7LbACVedv/y8B/R8SRiDgBPAC8b+ZKnq7LbDCVCf+LwLWSRtU6\ny2IlsLeassysbmU+8++gNTnnTuCZ4nfdWVFdZlazstN1fQb4TEW1mFmDfIafWaYcfrNMNTqqb2pq\nirfeeqvvdq+99lrfbS688MK+20DaCMLUUX1Nzp+XMkIM0voeYNmyZX232bVrV9K2jh071nebFStW\nJG3rzTffTGo3PDzcd5uUrPTzOHvPb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yp\nh98sUw6/WaYcfrNMNTqwZ2hoiPnz+/9q/5RBOiMjaX/a0FBzr4cpA3RSpf5dGzZsSGp38803991m\n27ZtSdu68cYb+26T+vxIneYrZZq6lAFj/Qwg8p7fLFMOv1mmzhp+SfdIOizp2bb7LpC0XdK+4nJR\nvWWaWdV62fP/PbBmxn2bgEcj4nLg0eK2mc0iZw1/RPwb8IMZd68D7i2u3wt8sOK6zKxmqZ/53xUR\nhwCKy3dWV5KZNaH2A36erstsMKWG/xVJFwMUl4e7rejpuswGU2r4twIbi+sbga9VU46ZNaWXf/Xd\nB/wHcIWkCUkfBf4YWCVpH7CquG1ms8hZz3GMiG7nd66suBYza5DP8DPLlMNvlqlGR/VB2ki2lBFY\nqaPYJicnk9rNVan9mDI92Lp165K29fjjj/fdZtWqVUnbSpXSjyl92M8UcN7zm2XK4TfLlMNvlimH\n3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTc3ZgT6qU6cRmg9SpwUZHRyuupHqr\nV6/uu00/A2DapfZjSruUwUD9bMd7frNMOfxmmXL4zTKVOlff5yU9J+lpSQ9KWlhvmWZWtdS5+rYD\n742InwW+B3y64rrMrGZJc/VFxCMRMf19V08Ai2uozcxqVMVn/luAh7st9HRdZoOpVPgl3QFMApu7\nrePpuswGU/LZM5I2AjcAKyP1jAkze9skhV/SGuBTwC9GxI+qLcnMmpA6V9/fAOcD2yXtkvTlmus0\ns4qlztV3dw21mFmDfIafWaYaH9VneUg5Bpw6Yi5F6rZSp3NrcmRqr7znN8uUw2+WKYffLFMOv1mm\nHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTA3eUKMOpqam+m6TMs+ZnS71G9pS\nHrNUTT7WqaPzJiYm+m6zeHG9X4rthJhlyuE3y1TSdF1tyz4hKSSN1VOemdUldbouJC0BVgEvVlyT\nmTUgabquwp8DnwT8nf1ms1DSZ35JNwEHI2J3D+t6ui6zAdR3+CWNAncAf9jL+p6uy2wwpez5fxq4\nFNgt6QCtGXp3Snp3lYWZWb36PmMhIp4B3jl9u3gBGI+IoxXWZWY1S52uy8xmudTputqXL6usGjNr\njM/wM8vUrBjY0+Q0TnN1EFHqAJ0mpfbjoE8NBmmDdA4ePNh3mxMnTvS87uA/a82sFg6/WaYcfrNM\nOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTKlJkd7SToC/E+XxWPAIHwb\nkOs4les41aDX8VMR0dOXZTYa/jOR9GREjLsO1+E6mqnDb/vNMuXwm2VqkMJ/59tdQMF1nMp1nGrO\n1DEwn/nNrFmDtOc3swY1Gn5JayR9V9J+SZs6LD9X0leK5TskLauhhiWSvilpr6Q9km7rsM4HJB2T\ntKv46WlqssR6Dkh6ptjOkx2WS9JfFX3ytKTlFW//ira/c5ek1yXdPmOd2vqj0xTwki6QtF3SvuJy\nUZe2G4t19knaWEMdn5f0XNHvD0pa2KXtGR/DCur4rKSDbf2/tkvbM+brNBHRyA8wDDwPXAbMA3YD\nV85Y57eBLxfX1wNfqaGOi4HlxfXzge91qOMDwLaG+uUAMHaG5WuBhwEB1wI7an6Mvk/rf8WN9Adw\nHbAceLbtvj8BNhXXNwGf69DuAuCF4nJRcX1RxXWsBkaK65/rVEcvj2EFdXwW+EQPj90Z8zXzp8k9\n/zXA/oh4ISKOA/cD62assw64t7i+BVipir9jOSIORcTO4voPgb3AJVVuo2LrgH+IlieAhZIurmlb\nK4HnI6LbiViVi85TwLc/D+4FPtih6a8A2yPiBxHxGrAdWFNlHRHxSERMFjefoDUvZa269EcvesnX\nKZoM/yXAS223Jzg9dD9ep+j0Y8CFdRVUfKy4CtjRYfEKSbslPSzpZ+qqAQjgEUlPSfpYh+W99FtV\n1gP3dVnWVH8AvCsiDkHrxZq2uSHbNNkvALfQegfWydkewyrcWnz8uKfLx6C++6PJ8Hfag8/8V0Mv\n61RC0gLgq8DtEfH6jMU7ab31/Tngr4F/qaOGwvsjYjlwPfA7kq6bWWqHNpX3iaR5wE3AP3dY3GR/\n9KrJ58odwCSwucsqZ3sMy/oSrdmxfx44BPxZpzI73HfG/mgy/BPAkrbbi4GXu60jaQR4B2lvgc5I\n0jm0gr85Ih6YuTwiXo+I/y2uPwScI2ms6jqK3/9ycXkYeJDW27d2vfRbFa4HdkbEKx1qbKw/Cq9M\nf7QpLg93WKeRfikOJN4A/HoUH65n6uExLCUiXomIkxExBfxtl9/fd380Gf5vA5dLurTYy6wHts5Y\nZyswfdT2Q8A3unV4quIYwt3A3oj4Qpd13j19rEHSNbT66dUq6yh+93mSzp++TusA07MzVtsK/GZx\n1P9a4Nj0W+KKbaDLW/6m+qNN+/NgI/C1Dut8HVgtaVHxNnh1cV9lJK0BPgXcFBE/6rJOL49h2Tra\nj/H8Wpff30u+TlXFEco+jmSupXV0/XngjuK+P6LVuQDzab3t3A/8J3BZDTX8Aq23Q08Du4qftcDH\ngY8X69wK7KF1xPQJ4H019cdlxTZ2F9ub7pP2WgR8seizZ4DxGuoYpRXmd7Td10h/0HrBOQScoLX3\n+iit4zyPAvuKywuKdceBu9ra3lI8V/YDH6mhjv20PkdPP0+m/xP1HuChMz2GFdfxj8Vj/zStQF88\ns45u+TrTj8/wM8uUz/Azy5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8Jtl6v8Bel1aZXOo26kA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ea179b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this part is just how I checked if it is a good model -> usually it is better to check with a different dataset than the one used to build the model\n",
    "predicted = dtfitted.predict(texts_test)\n",
    "print(np.mean(predicted == types_test))\n",
    "conf = sklearn.metrics.confusion_matrix(predicted, types_test)\n",
    "plt.imshow(conf, cmap='binary', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalmodel.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the model\n",
    "joblib.dump(dtfitted, 'finalmodel.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
