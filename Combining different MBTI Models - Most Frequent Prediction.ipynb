{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conbining different MBTI Models - Most Frequent Prediction Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Sara JakÅ¡a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are going to be combining different models or order to bust our prediction rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is here because it is a value that I am frequently using in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [\"ENFJ\",\n",
    "             \"ENFP\",\n",
    "             \"ENTJ\",\n",
    "             \"ENTP\",\n",
    "             \"ESFJ\",\n",
    "             \"ESFP\",\n",
    "             \"ESTJ\",\n",
    "             \"ESTP\",\n",
    "             \"INFJ\",\n",
    "             \"INFP\",\n",
    "             \"INTJ\",\n",
    "             \"INTP\",\n",
    "             \"ISFJ\",\n",
    "             \"ISFP\",\n",
    "             \"ISTJ\",\n",
    "             \"ISTP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function here is used to get all the different data for each different label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_type_texts(filename):\n",
    "    posts = []\n",
    "    with open(\"PersonalityCafePosts/\" + filename, \"r\") as read:\n",
    "        content = read.readlines()\n",
    "    content = \"\".join(content)\n",
    "    content = content.split(\"\\n\\n\\n\")\n",
    "    content = [post.strip() for post in content]\n",
    "    posts = posts + content\n",
    "    with open(\"Reddit/reddit.csv\", \"r\") as read:\n",
    "        content = read.readlines()\n",
    "    for line in content:\n",
    "        typename = line.split(\"\\t\")\n",
    "        if typename[2].strip().lower() == filename.lower():\n",
    "            posts.append(line.strip())\n",
    "    if filename in [\"ESFJ\"]:\n",
    "        with open(\"Tumblr/\" + filename.lower() + \"-posts.csv\", \"r\") as read:\n",
    "            content = read.readlines()\n",
    "            posts = posts + content\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function let us get the number selection of the posts. It is used in order to create submodels which will have balaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_posts(typename, number_of_posts):\n",
    "    posts = get_type_texts(typename)\n",
    "    return random.sample(posts, number_of_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function simply allows us to check how many instances of each type are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_number_of_texts():\n",
    "    typeposts = defaultdict(int)\n",
    "    for filename in filenames:\n",
    "        typeposts[filename] = len(get_type_texts(filename))\n",
    "    return typeposts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will check how many element does the category with least elements has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360\n"
     ]
    }
   ],
   "source": [
    "min_data = min([element for element in get_number_of_texts().values()])\n",
    "print(min_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will allow us to create a model, test it on a seperate part of the data and the output the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(min_data, function_used, ngram_range_value=(1,2)):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for filename in filenames:\n",
    "        current_data = get_random_posts(filename, min_data)\n",
    "        all_data = all_data + current_data\n",
    "        all_labels = all_labels + [filename]*len(current_data)\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(all_data, all_labels, test_size=0.25)\n",
    "    model = Pipeline([('vect', CountVectorizer(stop_words=\"english\", ngram_range=ngram_range_value)),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('fitting', function_used),\n",
    "                  ])\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be the list where we will keep track of all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to be creating the models and saving them in the all_models variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.352205882353\n",
      "0.356801470588\n",
      "0.26875\n",
      "0.254044117647\n",
      "0.272242647059\n",
      "0.361397058824\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    all_models.append(create_model(min_data, LogisticRegression()))\n",
    "    all_models.append(create_model(min_data, SGDClassifier()))\n",
    "    all_models.append(create_model(min_data, MultinomialNB()))\n",
    "    all_models.append(create_model(min_data, RandomForestClassifier()))\n",
    "    all_models.append(create_model(min_data, DecisionTreeClassifier()))\n",
    "    all_models.append(create_model(min_data, LinearSVC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to save these models in the \"mbti-16-models.obj\" file, so that we will not need to calculate them every single time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbti-6-models.obj\", \"wb\") as output_file:\n",
    "    for model in all_models[:7]:\n",
    "        pickle.dump(model, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will simply take the dictionary with all predictions and output the most frequent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_most_frequent_pred(dictionary):\n",
    "    most_freq_num = 0\n",
    "    most_freq_type = \"\"\n",
    "    for typename, freq in dictionary.items():\n",
    "        if freq > most_freq_num:\n",
    "            most_freq_num = freq\n",
    "            most_freq_type = typename\n",
    "    return most_freq_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is simply to test how well the combined models do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_labels = []\n",
    "for filename in filenames:\n",
    "    current_data = get_random_posts(filename, min_data)\n",
    "    all_data = all_data + current_data\n",
    "    all_labels = all_labels + [filename]*len(current_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_data = list(zip(all_data, all_labels))\n",
    "random.shuffle(whole_data)\n",
    "all_data = [d[0] for d in whole_data]\n",
    "all_labels = [d[1] for d in whole_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = []\n",
    "i = 0\n",
    "for data in all_data[:500]:\n",
    "    i += 1\n",
    "    all_pred = defaultdict(int)\n",
    "    for model in all_models[:50]:\n",
    "        something = []\n",
    "        something.append(data)\n",
    "        pred = model.predict(something)\n",
    "        all_pred[pred[0]] += 1\n",
    "    pred = get_most_frequent_pred(all_pred)\n",
    "    predicted.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.502\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([1 if x == y else 0 for x, y in zip(predicted, all_labels[:500])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWaEcfrNCOfxmhXL4zQrl8JsV6v8BZCbMVFQ+BdYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a3fb79c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(predicted, all_labels[:500])\n",
    "plt.imshow(conf, cmap='binary', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if a person just want to import an use them, the the following function can be use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbti-6-models.obj\", \"rb\") as f:\n",
    "    for i in range(6):\n",
    "        models.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then text can be predicted in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pred = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    prediction = model.predict([\"\"\"The third-rate mind is only happy when it is thinking with the majority. \n",
    "                                The second-rate mind is only happy when it is thinking with the minority. \n",
    "                                The first-rate mind is only happy when it is thinking.\"\"\"])\n",
    "    all_pred[prediction[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ESFJ'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent_pred(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
